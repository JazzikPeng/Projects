---
title: "parallel"
output:
  html_notebook: default
  html_document: default
---

# Loop Scheduling

$$
  \begin{cases}
    \text{Static scheduling} 
      \begin{cases}
        \text{Chunking}\\
        \text{Reverse scheduling}
      \end{cases}
    
    \\
      
    \text{Dynamic scheduling}
        \begin{cases}
        \text{Chunking}\\
        \text{Reverse scheduling}
      \end{cases}
  \end{cases}
$$

* Static scheduling: The assignment of loop iterations to processes is arranged before execution starts.

* Dynamic scheduling: The assignment of loop iterations to processes is arranged during execution. Each time a process finishes a loop iteration, it picks up a new one (or several, with chunking) to work on.

* Chunking: Assign a group of loop iterations to a process, rather than a single loop iteration. In dynamic scheduling, say, when a process becomes idle, it picks up a group of loop iterations to work on next.

* Reverse scheduling: In some applications, the execution time for an iteration grows larger as the loop index grows. For reasons that will become clear below, it is more efficient to reverse the order of the iterations.


**Remark**

1. It seems that dynamic scheduling outperforms static scheduling. However, dynamic method, may exact a substantial overhead penalty. In package `snow`, for instance, there would need to be communication between a worker and the manager, in order for the worker to determine which task is next assigned to it. Static scheduling doesn’t have this drawback.

2. Suggested strategy: chunking in the dynamic. By assigning loop iterations to processes in groups instead of singly, processes need to go to the work queue less often, thus accruing less overhead.

## `Snow`

`Snow` employs a scatter/gather paradigm: We have multiple instances of R running at the same time, either on several machines in a cluster, or on a multicore machine. We’ll refer to one of the instances as the manager, with the rest being workers. The parallel computation then proceeds as follows:

* scatter: The manager breaks the desired computation into chunks, and sends (“scatters”) the chunks to the workers.

* chunk computation: The workers then do computation on each chunk, and send the results back to the manager.

* gather: The manager receives (“gathers”) those results, and combines them to solve the original problem.

## Example: compute links 


|  source  |  function syntax |     explanation      |
| ---------- | ---------------- | -------------------------------------------------------------|
| parallel | makecluster(nworkers) |set up cluster of nworkers workers on multicore machine |
| parallel | clusterExport(cl, varlist) |make variables in the varlist global to each cluster|
| parallel | clusterApply(cl, x, fun) | parallel version of apply |
| parallel | clusterSplit(cl, seq) | splits seq into a consecutive piece for each cluster and returns the result as a list with length equal to the number of nodes|
| base | Reduce(fun, x)|  a convenient way to combine the results returned by the workers.|


1. `lnks`: A matrix representing outlinks of the various sites, with `links[i,j]` being 1 or 0, according to whether there is an outlink from site i to site j.

2. `ichunk`: A group of loops assigned in the i-th chunck.

3. `cls`: Number of workers will be used, generated by the function `makecluster(nworkers)`.

### pseduo-chunking
```{r pseduo-chunking}
library(parallel)
# what i worker shall do
doichunk <- function(ichunk){
  toti <- 0
  nr <- nrow(lnks) 
  for (j in ichunk){
    tmp <- lnks[(j+1):nr , ] %*% lnks[j,]
    toti <- toti + sum(tmp)
  }
  toti
}

# scatter and gather

manage4lnk <- function(cls,lnks){
  nr <- nrow(lnks)
  clusterExport(cls,'lnks')
  chunks <- 1 : (nr-1)
  tots <- clusterApply(cls,chunks,doichunk)
  Reduce(sum,tots)
}

# sim-test

lnksim <- function(nr,nc,nworkers){
  set.seed(1)
  lnks <<- matrix(sample(0:1,(nr*nc),replace = T),nrow = nr)
  cls <- makeCluster(nworkers)
  system.time(manage4lnk(cls,lnks))
}
```

**Remark**

1. Here `clusterApply()` will treat that `chunks` vector as an R list of `nr - 1` elements. In the call to that function, we have the manager sending chunks[[1]] to cls[[1]], which is the first worker. Similarly, ichunks[[2]] is sent to cls[[2]], the second worker, and so on.

2. Unless the problem is small (far too small to parallelize!), we will have more chunks than workers here. The `clusterApply()` function handles this in a cyclic manner. Say we have 1000 chunks and 4 workers. After `clusterApply()` sends the fourth chunk to the fourth worker, it starts over again, sending the fifth chunk to the first worker, the sixth chunk to the second worker, and so on, repeatedly cycling through the workers. In fact, the internal code uses R’s recycling operation to implement this.

3. Each worker is told to run `doichunk()` on each chunk sent to that worker by the manager. The second worker, for example, will call doichunk() on ichunks[[2]], ichunks[[6]], etc.

```{r pseduo-chunking_test}
# tests
lnksim(1000,1000,2)
```

### real-chunking



```{r real-chunking}
library(parallel)
# what i worker shall do
doichunk <- function(ichunk){
  toti <- 0
  nr <- nrow(lnks) 
  for (j in ichunk){
    tmp <- lnks[(j+1):nr , ] %*% lnks[j,]
    toti <- toti + sum(tmp)
  }
  toti
}

# scatter and gather

manage4lnk_sp <- function(cls,lnks){
  nr <- nrow(lnks)
  clusterExport(cls,'lnks')
  chunks <- clusterSplit(cls,1 : (nr-1))
  tots <- clusterApply(cls,chunks,doichunk)
  Reduce(sum,tots)
}

# sim-test

lnksim_sp <- function(nr,nc,nworkers){
  set.seed(1)
  lnks <<- matrix(sample(0:1,(nr*nc),replace = T),nrow = nr)
  cls <- makeCluster(nworkers)
  system.time(manage4lnk_sp(cls,lnks))
}
```

**Remark**
So, what does `clusterSplit()` do? Say `lnks` has 500 rows and we have 4 workers. The goal here is to partition the row numbers 1,2,...,500 into 4 equal (or roughly equal) subsets, which will serve as the chunks of indices for each worker to process. Clearly, the result should be 1-125, 126-250, 251-375 and 376-500, which will correspond to the values of j in the outer for loop in our serial code, `doichunk`. `Worker 1` will process the outer loop iterations for j = 1,2,...,125, and so on.


```{r real-chunking_test}
# tests
lnksim_sp(1000,1000,2)
```


# Shared Memory

As with `snow`, in `Rdsm` each process is a separate, independent instantiation of R. However, the difference is that with Rdsm, the processes must run on the same machine, and they share variables, in fact doing so via physical shared memory.

The shared variables must take the form of matrices.  A shared matrix will have the class `”big.matrix”`.

Note that one must use brackets in referencing the shared matrices. For instance, to print the shared matrix m, write

```
print(m[,])
```

| source   | function syntax |     explanation      |
| ---------- | ---------------- | -------------------------------------------------------------|
| Rdsm | mgrinit(cls) | Initializes Rdsm on the given parallel cluster |
| Rdsm | mgrmakevar(cls,varname,nrow,ncol) |Creates an Rdsm shared variable.|
| Rdsm |mgrmakelock(cls,lockname) | Creates an Rdsm lock. |
| parallel |splitIndices(nx, cls) |  This divides up 1:nx into ncl lists of approximately equal size, as a way to allocate tasks to nodes in a cluster. |
| parallel | clusterEvalQ(cl, expr) | evaluates a literal expression on each cluster node. |


## Example: Matrix Multiplication 

### rdsm version


```{r matrix_multiplication_rdsm}
mmulthread <- function(u,v,w){
  require(parallel)
  myidxs <- splitIndices(nrow(u),myinfo$nwrkrs) [[myinfo$id]]
  w[myidxs, ] <- u[myidxs, ] %*% v[,]
  0
}

mtest <- function(nworkers){
  require(parallel)
  cls <- makeCluster(nworkers)
  mgrinit(cls) #  initialize the Rdsm system
  # create three matrices in shared memory, a, b and c 
  mgrmakevar(cls,"a",6,2)
  mgrmakevar(cls,"b",2,6)
  mgrmakevar(cls,"c",6,6)
  a[,] <- 1:12
  b[,] <- rep(1,12)
  clusterExport(cls,"mmulthread") #  ship the function mmulthread() itself to the threads
  clusterEvalQ(cls,mmulthread(a,b,c)) # launch the threads
  print(c[,])
}
```

```{r matrix_multiplication_rdsm,test}
library(Rdsm)
mtest(2)
```

**Remark**

The built-in Rdsm variable `myinfo` is an R list containing nwrkrs, the total number of threads, and id, the ID number of the thread executing.

### parallel verison


```{r matrix_multiplication_pa}
doischunk <- function(idx){
  u[idx,] %*% v
}

managemp <- function(cls,u,v){
  clusterExport(cls,"u")
  clusterExport(cls,"v")
  idxs <- clusterSplit(cls,1:nrow(u))
  ws <- clusterApply(cls,idxs,doischunk)
  Reduce(rbind,ws)
}

mtest_pa <- function(nworkers){
  require(parallel)
  cls <- makeCluster(nworkers)
  u <<- matrix(1:12,nrow=6)
  v <<- matrix(rep(1,12),ncol=6)
  print(managemp(cls,u,v))
}

mtest_pa(2)
```

### Time comparison

```{r matrix_multiplication_compare}
mmulthread <- function(u,v,w){
  require(parallel)
  myidxs <- splitIndices(nrow(u),myinfo$nwrkrs) [[myinfo$id]]
  w[myidxs, ] <- u[myidxs, ] %*% v[,]
  0
}
test_rdsm <- function(nworkers){
  require(parallel)
  require(Rdsm)
  cls <- makeCluster(nworkers)
  mgrinit(cls) 
  mgrmakevar(cls,"u",n,n)
  mgrmakevar(cls,"v",n,n)
  mgrmakevar(cls,"w",n,n)
  u[,] <- a
  v[,] <- b
  clusterExport(cls,"mmulthread")
  clusterEvalQ(cls,mmulthread(u,v,w))
  return(w)
}

test_pa <- function(nworkers){
  doischunk <- function(idx){
    a[idx,] %*% b
  }
  managemp <- function(cls,a,b){
    clusterExport(cls,"a")
    clusterExport(cls,"b")
    idxs <- clusterSplit(cls,1:nrow(a))
    ws <- clusterApply(cls,idxs,doischunk)
    Reduce(rbind,ws)
  }
  require(parallel)
  cls <- makeCluster(nworkers)
  c <- managemp(cls,a,b)
  return(c)
}
n <- 2500
nworkers <- 2
set.seed(1)
a <<- matrix(runif(n^2),ncol = n)
set.seed(2)
b <<- matrix(runif(n^2),ncol = n)
```
```{r}
system.time(test_rdsm(nworkers))
```

```{r}
system.time(test_pa(nworkers))
```

```{r}
system.time(a%*%b)
```

## Locks and Barriers

| source   | function syntax |     explanation      |
| ---------- | ---------------- | -------------------------------------------------------------|
| Rdsm | mgrmakelock(cls,lockname) | Creates an Rdsm lock. |
| Rdsm | rdsmlock(lockname) | Lock/unlock operations to avoid race conditions among the threads.|
| Rdsm | rdsmunlock(lockname) | Lock/unlock operations to avoid race conditions among the threads.|
| Rdsm | getidxs(m) |(The same as splitIndices) The sequence 1:m will be partitioned, and one portion will be assigned to the calling thread.|

### Locks

```{r withou-lock}
library(parallel)
library(Rdsm)
s <- function(n){
  for (i in 1:n){
    tot [1,1] <- tot [1,1] + 1
  }
}
cls <- makeCluster(2)
clusterExport(cls,"s")
mgrinit(cls)
mgrmakevar(cls,"tot",1,1)
tot [1,1] <- 0
clusterEvalQ(cls,s(1000))
tot[1,1]
```

```{r with-lock}
rm(list=ls())
s_lock <- function(n) {
  require(Rdsm)
  for (i in 1:n) {
    rdsmlock("totlock")
    tot[1,1] <- tot[1,1] + 1
    rdsmunlock("totlock")
  }
}

library(Rdsm)
library(parallel)
cls2 <- makeCluster(2)
mgrinit(cls2)
mgrmakevar(cls2,"tot",1,1)
mgrmakelock(cls2,"totlock")
tot[1,1] <- 0
clusterExport(cls2,"s_lock")
clusterEvalQ(cls2,s_lock(1000))
tot[1,1] 
```

### Barriers

**Barriers are used to synchronize all the threads**

Consider a time series of length n. We may be interested in bursts, periods in which a high average value is sustained. We might stipulate that we look only at periods of length k consecutive points, for a user-specified k. So, we wish to find the period of length k that has the maximal mean value.

```{r maximal_mean_value}
rm(list=ls())
maxburst <- function(x,k,mas,rslts){
  require (Rdsm)
  require (zoo)
  # determine this thread's chunk of x
  n <- length(x)
  myidxs <- getidxs (n-k+1) # determine the chunk
  myfirst <- myidxs [1]
  mylast <- myidxs[length(myidxs)] 
  mas[1,myfirst:mylast] <- 
    rollmean (x[myfirst:(mylast+k-1)],k)
  # make sure all threads have written to mas
  barr ()
  # one thread must do wrap-up , say thread 1
  if (myinfo$id == 1) {
    rslts[1,1] <- which.max(mas[,])
    rslts[1,2] <- mas[1,rslts[1,1]]
  }
}

library(Rdsm)
library(parallel)
c2 <- makeCluster(2)
mgrinit(c2)
mgrmakevar(c2,"mas",1,9)
mgrmakevar(c2,"rslts",1,2)
x <<- c(5,7,6,20,4,14,11,12,15,17)
clusterExport(c2,"maxburst")
clusterExport(c2,"x")
clusterEvalQ(c2,maxburst(x,2,mas,rslts))
r <- rslts[,] ; r <- as.matrix(r)
rownames(r) <- c("start position","maximal mean")
r
```

```{r trans_adj_matrix}
rm(list=ls())
findlinks <- function(adj, lnks, counts){
  require(parallel)
  nr <- nrow(adj)
  myidxs <- getidxs(nr)
  myout <- apply(adj[myidxs,],1,function(onerow) which(onerow == 1))
  tmp <- matrix(nrow=0,ncol=2)
  my1strow <- myidxs[1]
  for (idx in myidxs){
    tmp <- rbind(tmp,convert1row(idx,myout[[idx-my1strow+1]]))
  }
  nmyedges <- Reduce(sum,lapply(myout,length)) # numbers of edges found by this thread 
  me <- myinfo$id
  counts[1,me] <- nmyedges # make sure all threads have written to counts
  barr()
  # thread 1 do the warpup -- determine where in lnks the portion of thread 1 ends
  if (me == 1) counts[1,] <- cumsum(counts[1,])
  barr()
  mystart <- if (me == 1) 1 else counts[1,me-1] + 1
  myend <- mystart + nmyedges - 1
  lnks[mystart:myend,] <- tmp
  0
}
convert1row <- function(rownum, colswith1s){ 
  if (is.null(colswith1s)) return(NULL)
  cbind(rownum, colswith1s ) # use recycling 
}

require (Rdsm)
library(parallel)
cls <- makeCluster(2)
mgrinit (cls)
mgrmakevar(cls,"x",6,6)
mgrmakevar(cls,"lnks",36,2)
mgrmakevar(cls,"counts",1,length(cls))
x[,] <- matrix(sample(0:1,36,replace=T),ncol=6) 
clusterExport(cls,"findlinks")
clusterExport(cls,"convert1row") 
clusterEvalQ(cls,findlinks(x,lnks,counts)) 
print(lnks[1:counts[1,length(cls )],])
```
### Example: k-means

```{r kmeans}
rm(list = ls())
library(Rdsm)
# initial centroids taken to be k randomly chosen rows of x; if a
# cluster becomes empty, its new centroid will be a random row of
# x

# arguments:
#    x:  data matrix x; shared
#    k:  number of clusters
#    ni:  number of iterations
#    cntrds:  centroids matrix; row i is centroid i; shared, k by ncol(x)
#    cinit:  optional initial values for the centroids; k by ncol(x)
#    sums:  scratch matrix; sums[j,] contains the count 
#       and sum for cluster j; shared, k by 1+ncol(x)
#    lck:  lock variable; shared

# the result will be in cntrds
kmeans <- function(x,k,ni,cntrds,sums,lck,cinit=NULL) {
   require(parallel)
   require(pdist)
   nx <- nrow(x)
   # get my assigned portion of x
   # myidxs <- splitIndices(nx,myinfo$nwrkrs)[[myinfo$id]]
   myidxs <- getidxs(nx)
   myx <- x[myidxs,]  
   # random initial centroids if none specified
   if (is.null(cinit)) {
      if (myinfo$id == 1) 
         cntrds[,] <- x[sample(1:nx,k,replace=F),]
      barr()
   } else cntrds[,] <- cinit

   # mysum()sums the rows in myx corresponding to the indices idxs; we
   # also add a count of those rows using length(idx)
   mysum <- function(idxs,myx) {
      c(length(idxs),colSums(myx[idxs,,drop=F]))
   }
   for (i in 1:ni) {  # ni iterations
      # node 1 is sometimes asked to do some "housekeeping"
      if (myinfo$id == 1) {
         sums[] <- 0
      }
      barr()  # other nodes wait for node 1 to do its work
      
      # find distances from my rows of x to the centroids, then
      # find which centroid is closest to each such row
      dsts <- matrix(pdist(myx,cntrds[,])@dist,ncol=nrow(myx))
      nrst <- apply(dsts,2,which.min)
      # nrst[i] contains the index of the nearest centroid to row i in
      # myx
      tmp <- tapply(1:nrow(myx),nrst,mysum,myx)
      # in the above, we gather the observations in myx whose closest
      # centroid is centroid j, and find their sum, placing it in
      # tmp[j]; the latter will also have the count of such observations
      # in its leading component 
      # next, we need to add that to sums[j,], as an atomic operation
      rdsmlock(lck)
      # the j values in tmp will be strings, so convert
      for (jn in names(tmp)) {
         j <- as.integer(jn)
         sums[j,] <- sums[j,] + tmp[[jn]]
      }
      rdsmunlock(lck)
      barr()  # wait from sums[,] to be ready
      if (myinfo$id == 1) {
         # update centroids, using a random data point if a cluster
         # becomes empty
         for (j in 1:k) {
           # update centroid for cluster j
           if (sums[j,1] > 0) {
              cntrds[j,] <- sums[j,-1] / sums[j,1] 
            } else cntrds[j] <<- x[sample(1:nx,1),]
         }
      }
   }
   0  # don't do expensive return of result
}
```
```{r kmeans_test}
library(Rdsm)
library(parallel)
nworkers <- 2
cls <- makeCluster(nworkers)
mgrinit(cls)
mgrmakevar(cls,"x",12,2)
mgrmakevar(cls,"cntrds",2,2)
mgrmakevar(cls,"sums",2,3)
mgrmakelock(cls,"lck")
x[,] <- matrix(sample(1:100,24,replace=TRUE),ncol=2)
clusterExport(cls,"kmeans")
clusterEvalQ(cls,kmeans(x,2,500,cntrds,sums,"lck"))
print(cntrds[,])
```

