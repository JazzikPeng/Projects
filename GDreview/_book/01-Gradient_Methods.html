<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A skecth of the Gradent Descent Methods</title>
  <meta name="description" content="A skecth of the Gradent Descent Methods.">
  <meta name="generator" content="bookdown 0.3.20 and GitBook 2.6.7">

  <meta property="og:title" content="A skecth of the Gradent Descent Methods" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="pics/misaki.jpg" />
  <meta property="og:description" content="A skecth of the Gradent Descent Methods." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A skecth of the Gradent Descent Methods" />
  
  <meta name="twitter:description" content="A skecth of the Gradent Descent Methods." />
  <meta name="twitter:image" content="pics/misaki.jpg" />

<meta name="author" content="Yutong Dai">


<meta name="date" content="2017-05-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="02-Block_Coordinate_Descent.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Text Book</a></li>
<li><a href="./">Roth</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html"><i class="fa fa-check"></i><b>1</b> Gradient Decent Methods</a><ul>
<li class="chapter" data-level="1.1" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#problem-with-additional-assumptions"><i class="fa fa-check"></i><b>1.1</b> Problem with additional assumptions</a><ul>
<li class="chapter" data-level="1.1.1" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#lipschtiz-constant"><i class="fa fa-check"></i><b>1.1.1</b> Lipschtiz constant</a></li>
<li class="chapter" data-level="1.1.2" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#convexity"><i class="fa fa-check"></i><b>1.1.2</b> Convexity</a></li>
<li class="chapter" data-level="1.1.3" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#strong-convexity"><i class="fa fa-check"></i><b>1.1.3</b> Strong Convexity</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#convex-situations"><i class="fa fa-check"></i><b>1.2</b> Convex situations</a><ul>
<li class="chapter" data-level="1.2.1" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#step-size-selection-rule-and-the-rate-of-convergence"><i class="fa fa-check"></i><b>1.2.1</b> step-size selection rule and the rate of convergence</a></li>
<li class="chapter" data-level="1.2.2" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#why-linear-rate-of-convergence"><i class="fa fa-check"></i><b>1.2.2</b> Why linear rate of convergence?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#acceleartion"><i class="fa fa-check"></i><b>1.3</b> Acceleartion</a><ul>
<li class="chapter" data-level="1.3.1" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#motivation-for-acceleration."><i class="fa fa-check"></i><b>1.3.1</b> Motivation for acceleration.</a></li>
<li class="chapter" data-level="1.3.2" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#why-we-can-accelerate"><i class="fa fa-check"></i><b>1.3.2</b> Why we can accelerate?</a></li>
<li class="chapter" data-level="1.3.3" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#heavy-ball-methods-v.s-nagd-method"><i class="fa fa-check"></i><b>1.3.3</b> Heavy Ball Methods v.s NAGD Method</a></li>
<li class="chapter" data-level="1.3.4" data-path="01-Gradient_Methods.html"><a href="01-Gradient_Methods.html#when-does-the-nagd-methods-fail"><i class="fa fa-check"></i><b>1.3.4</b> When does the NAGD Methods fail?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-Block_Coordinate_Descent.html"><a href="02-Block_Coordinate_Descent.html"><i class="fa fa-check"></i><b>2</b> Block Coordinate Descent Methods</a></li>
<li class="chapter" data-level="3" data-path="03-Comments.html"><a href="03-Comments.html"><i class="fa fa-check"></i><b>3</b> Test</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A skecth of the Gradent Descent Methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gradient-decent-methods" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Gradient Decent Methods</h1>
<table>
<thead>
<tr class="header">
<th align="center">Problem Formulation</th>
<th align="left"><span class="math inline">\(\min_{x\in R^n} f(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Function class</td>
<td align="left">Continuously Differentiable and bouded below <span class="math inline">\(R^n\)</span></td>
</tr>
<tr class="even">
<td align="center">Goal</td>
<td align="left">Find local minimum <span class="math inline">\(x^{*}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Scheme</td>
<td align="left">Choose <span class="math inline">\(x^0\in R^n\)</span>, and run <span class="math inline">\(x^{k+1} = x^k - \alpha^k\nabla f(x^k)\)</span></td>
</tr>
</tbody>
</table>
<div id="problem-with-additional-assumptions" class="section level2">
<h2><span class="header-section-number">1.1</span> Problem with additional assumptions</h2>
<p>In many literatures, problems of interest are naturally endowed with some basic assumptions so that beautiful analytical results can be derived, such as the convergence rate. One might ask that why these assumptioms are important and what are intuitions behind these assumtions? We try to answer these questions in this section.</p>
<div id="lipschtiz-constant" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Lipschtiz constant</h3>
<p>Problems of interest are naturally endowed with the <em>Lipschitz continous gradient</em> property, that is</p>

<div class="definition">
<span id="def:unnamed-chunk-2" class="definition"><strong>Definition 1.1 </strong></span>We can <span class="math inline">\(f(x)\)</span> is gradient Lipschitz continous if<br />
<span class="math display">\[||\nabla f(x) - \nabla f(y) || \leq L || x - y|| \forall x,y\in R^n.\]</span> Here <span class="math inline">\(||.||\)</span> means the Euclidean norm.
</div>

<p><strong>Remark</strong> Intuitively, the Lipschitz continous gradient property enforces <span class="math inline">\(f(x)\)</span> not to be “too sharp”. For example, the <span class="math inline">\(f(x) = |x|\)</span> dosen’t enjoy this property.</p>
<p><strong>Remark</strong> If <span class="math inline">\(f(x)\)</span> is gradient Lipschitz continous, then it is upper bounded by a quadratic function <span class="math inline">\(\phi_1(x)\)</span>, that is</p>
<p><span class="math display">\[ f(x) \leq f(x_0) + \nabla f(x_0)^T(x-x_0) + \frac{L}{2} ||x-x_0||^2 := \phi_1(x) \quad \forall x,x_0\in R^n \]</span> also <span class="math inline">\(f(x)\)</span> is the upper bound of another quadratic function <span class="math inline">\(\phi_2(x)\)</span>, taking form of</p>
<p><span class="math display">\[ \phi_2(x) := f(x^0) + \nabla f(x_0)^T(x-x_0) - \frac{L}{2} ||x-x_0||^2. \]</span> See Figure<a href="01-Gradient_Methods.html#fig:geomlip">1.1</a> for example.</p>
<div class="figure" style="text-align: center"><span id="fig:geomlip"></span>
<img src="pics/geomlip.png" alt="An illustration of the gradient Lipschtiz continuous propety."  />
<p class="caption">
Figure 1.1: An illustration of the gradient Lipschtiz continuous propety.
</p>
</div>
<p>To verify this remark, we can apply the following lemma.</p>

<div class="lemma">
<p><span id="lem:bound" class="lemma"><strong>Lemma 1.1 </strong></span>If <span class="math inline">\(f(x)\)</span> is continuously differentiable and gradient Lipschtiz continuous, then for any <span class="math inline">\(x,y\)</span> the following holds:</p>
<span class="math display">\[ | f(x) - f(y) - (y-x)^T\nabla f(x)| \leq \frac{L}{2} || y-x ||^2\]</span>
</div>


<div class="corollary">
<p><span id="cor:unnamed-chunk-3" class="corollary"><strong>Corollary 1.1 </strong></span>From Lemma<a href="01-Gradient_Methods.html#lem:bound">1.1</a>, we assert that if <span class="math inline">\(f(x)\)</span> is continuously differentiable and gradient Lipschtiz continuous then the Hessian of <span class="math inline">\(f(x)\)</span> is bounded by <span class="math inline">\(LI_n\)</span>, where <span class="math inline">\(I_n\)</span> is <span class="math inline">\(n\times n\)</span> unit matrix.</p>
</div>

<p>A easy way to check the <em>gradient Lipschitz continous</em> assumption is to apply the Lemma<a href="01-Gradient_Methods.html#lem:L-inclusion">1.2</a><span class="citation">(Nesterov <a href="#ref-nesterov2013introductory">2013</a>)</span></p>

<div class="lemma">
<p><span id="lem:L-inclusion" class="lemma"><strong>Lemma 1.2 </strong></span>If <span class="math inline">\(f(x)\)</span> is twice differentiable and satisfies <span class="math inline">\(||\nabla f(x) - \nabla f(y) || \leq L || x - y||\)</span> if and only if</p>
<p><span class="math display">\[ ||\nabla^2 f(x) || \leq L, \forall x\in R^n. \]</span></p>
For matrix case, <span class="math inline">\(||A|| = \sqrt{\lambda_{max}(A^TA)},\forall A\in R^{n\times n}.\)</span>
</div>

</div>
<div id="convexity" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Convexity</h3>
<p>If <span class="math inline">\(f(x)\)</span> is convex, we enjoy the following nice property:</p>
<ul>
<li>The local minimum we find is also the global minimum;</li>
<li>Using the First order optimality condition, we can dramatically simplify our problem. That is, we only have to construct a sequence <span class="math inline">\(\{x^k\}\)</span> that satifies <span class="math inline">\(\lim_{k\rightarrow +\infty}||\nabla f(x^k)||=0\)</span></li>
</ul>
</div>
<div id="strong-convexity" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Strong Convexity</h3>
<p>We now only present a geometric interpretation of strong convexity and will go back to this point later when talking about the rate of convergence.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-4" class="definition"><strong>Definition 1.2 </strong></span>We can <span class="math inline">\(f(x)\)</span> is strongly convex if <span class="math display">\[ f(x) \geq f(x_0) + \nabla f(x_0)^T(x-x_0) + \frac{\ell}{2} ||x-x_0||^2  \forall x,x_0\in R^n \]</span></p>
</div>

<p>This means that we can squeeze a parabola between the tangent plane at <span class="math inline">\(x_0\)</span> given by the gradient and the function itself. Thus, the strong convexity assumption enforce the <span class="math inline">\(f(x)\)</span> not to be too “flat”.</p>
<div class="figure" style="text-align: center"><span id="fig:geomstrong"></span>
<img src="pics/geomstrong.png" alt="An illustration of the strongly convex propety."  />
<p class="caption">
Figure 1.2: An illustration of the strongly convex propety.
</p>
</div>
</div>
</div>
<div id="convex-situations" class="section level2">
<h2><span class="header-section-number">1.2</span> Convex situations</h2>
<p>Without additional assumptions, we can not guarantee convergence even to a local minimum and estimate the global performance of the proposed schemes. In general, the gradient method convergece only to a stationary point of <span class="math inline">\(f(x)\)</span>. Therefore, from now on, we only focus on convex cases.</p>
<div id="step-size-selection-rule-and-the-rate-of-convergence" class="section level3">
<h3><span class="header-section-number">1.2.1</span> step-size selection rule and the rate of convergence</h3>
<p>The step-size <span class="math inline">\(\alpha^k\)</span> plays a key role in the convergence of the gradient descent method. If <span class="math inline">\(\alpha^k\)</span> is too small, more iterations will be required to achieve the <span class="math inline">\(\epsilon\)</span>-accuracy (<span class="math inline">\(|f(x^k)-f(x^*)|\leq \epsilon\)</span>). If <span class="math inline">\(\alpha^k\)</span> is too large, the scheme fails to converge. We here present two theoretical optimal step-size selection rules.</p>
<ul>
<li><p>If convex <span class="math inline">\(f(x)\)</span> is gradient Lipschtiz continuous, then the optimal <span class="math inline">\(\alpha^k = \frac{1}{L}\)</span>.</p></li>
<li><p>If strongly convex <span class="math inline">\(f(x)\)</span> is gradient Lipschtiz continuous, then the optimal <span class="math inline">\(\alpha^k = \frac{2}{L+\ell}\)</span>.</p></li>
</ul>
<p>Here, <em>optimal</em> means</p>
<p><span class="math display">\[
\alpha^k = \mathop{\text{argmin}}_{\alpha} f(x^k - \alpha\nabla f(x^k)).
\]</span> It has been proved that</p>
<ul>
<li>For convex and gradient Lipschtiz continuous <span class="math inline">\(f(x)\)</span>, with chosen step-size <span class="math inline">\(\alpha^k = \frac{1}{L}\)</span> , the rate of convergence is sub-linear. To be specific,</li>
</ul>
<p><span class="math display">\[f(x_k) - f(x^*) \leq \frac{2L||x^0 - x^*||^2}{k+4}.\]</span></p>
<ul>
<li>For strongly convex and gradient Lipschtiz continuous <span class="math inline">\(f(x)\)</span>, with chosen step-size <span class="math inline">\(\alpha^k = \frac{2}{L + \ell}\)</span> , the rate of convergence is linear. To be specific,</li>
</ul>
<p><span class="math display">\[f(x_k) - f(x^*) \leq \frac{L}{2}\big(\frac{L-\ell}{L+\ell}\big)^{2k}||x^0 - x^*||^2.\]</span> Technically, the above results are mainly derived from two steps:</p>
<ul>
<li>Find how much you can improve in a single interation by establishing</li>
</ul>
<p><span class="math display">\[f(x^{k+1}) \leq  f(x^k) - \omega_1 ||\nabla f(x_k)|| \]</span></p>
<ul>
<li>Find how far at most we still need to go to recach the minimum by establishing</li>
</ul>
<p><span class="math display">\[f(x^k) - f(x^*) \leq \omega_2||\nabla f(x_k)||\]</span></p>
</div>
<div id="why-linear-rate-of-convergence" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Why linear rate of convergence?</h3>
<p>Before we answer this question, we first list the definition of a contraction mapping and the Banach fixed-point theorem.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-5" class="definition"><strong>Definition 1.3  (Contraction Mapping)  </strong></span>Let <span class="math inline">\((X, d)\)</span> be a metric space. Then a map <span class="math inline">\(T : X \rightarrow X\)</span> is called a contraction mapping on <span class="math inline">\(X\)</span> if there exists <span class="math inline">\(q \in [0, 1)\)</span> such that</p>
<p><span class="math display">\[ d(T(x),T(y))\leq qd(x,y) \forall x, y \in X.\]</span></p>
</div>


<div class="theorem">
<span id="thm:unnamed-chunk-6" class="theorem"><strong>Theorem 1.1  (Banach Fixed Point Theorem)  </strong></span>Let <span class="math inline">\((X, d)\)</span> be a non-empty complete metric space with a contraction mapping <span class="math inline">\(T : X \rightarrow X\)</span>. Then <span class="math inline">\(T\)</span> admits a unique fixed-point <span class="math inline">\(x^*\)</span> in <span class="math inline">\(X\)</span> (i.e. <span class="math inline">\(T(x^*) = x^*\)</span>). Furthermore, <span class="math inline">\(x^*\)</span> can be found as follows: start with an arbitrary element <span class="math inline">\(x_0\)</span> in <span class="math inline">\(X\)</span> and define a sequence <span class="math inline">\(\{x_n\}\)</span> by <span class="math inline">\(x_n = T(x_{n−1})\)</span>, then <span class="math inline">\(x_n \rightarrow x^*\)</span>. Moreover, <span class="math display">\[ d(x^{*},x_{n+1})\leq qd(x^{*},x_{n}) \]</span>
</div>

<p>Then we establish connections between contraction mapping and linear rate of convergence through the gradient decent method, which takes the form of</p>
<p><span class="math display">\[x^{k+1} = x^k - \alpha\nabla f(x^k),\]</span> If we define a mapping as <span class="math inline">\(g(x) = x - \alpha\nabla f(x)\)</span> and suppose <span class="math inline">\(g(x)\)</span> is contractive on <span class="math inline">\(R^n\)</span>. Assume there exists a stationary point <span class="math inline">\(x^*\)</span>, then starting from any point <span class="math inline">\(x^0\)</span>, we derive</p>
<p><span class="math display" id="eq:linear">\[
\begin{align}
||x^{k+1} - x^*|| &amp;= ||x^{k} - \alpha\nabla f(x^k) - x^*|| \\
                  &amp;= || g(x^k) - g(x^*)|| \\
                  &amp; \leq q||x^k - x^*|| \\
                  &amp; \leq q^{k+1}|| x^0 - x^* || \tag{1.1}
\end{align}
\]</span> <a href="01-Gradient_Methods.html#eq:linear">(1.1)</a> indicates that the rate of convergence is linear.</p>
<p>Finally, we assert that</p>

<div class="lemma">
<span id="lem:unnamed-chunk-7" class="lemma"><strong>Lemma 1.3 </strong></span>If <span class="math inline">\(f(x)\)</span> is twice continuously differentiable, the <span class="math inline">\(g(x)\)</span> is a contraction mapping if and only if <span class="math inline">\(f(x)\)</span> is strongly convex on <span class="math inline">\(R^n\)</span>.
</div>


<div class="proof">
Proof </em></span>  Suppose <span class="math inline">\(g(x)\)</span> is contractivie, then we derive,
<span class="math display" id="eq:convex">\[\begin{align}

\lim_{t\rightarrow 0^+} \frac{1}{t} || g(x + t\Delta x) - g(x) || 
&amp;=  \lim_{t\rightarrow 0^+}  || \Delta x - \frac{\alpha}{t}[\nabla f(x + t\Delta x) - \nabla f(x)] || \\
&amp;= || \Delta x - \alpha \nabla^2 f(x)\Delta x || \\
&amp; \leq q||\Delta x|| \tag{1.2}

\end{align}\]</span>
<p><a href="01-Gradient_Methods.html#eq:convex">(1.2)</a> holds by the contractivity and it means that <span class="math inline">\(||I_n - \alpha\nabla^2 f(x)||\leq q\)</span>. Therefore, we derive</p>
<p><span class="math display">\[ \frac{1-q}{\alpha}I_n  \leq \nabla^2 f(x) \leq \frac{1+q}{\alpha} I_n \]</span>. Therefore <span class="math inline">\(f(x)\)</span> is strongly convex.</p>
Suppose <span class="math inline">\(f(x)\)</span> is strongly convex, go backward of the above proof, we assert <span class="math inline">\(g(x)\)</span> is contractive.
</div>

<p><br />
We close this subsection by pointing out that the scheme discussed above are not optimal. Here the <em>optimal</em> is in terms of the lower complexity bound. In <span class="citation">(Nesterov <a href="#ref-nesterov2013introductory">2013</a>)</span>, Nesterov proves the following two theorems.</p>
<p><strong>Assumption LC</strong> An interative method generates a sequence of test points <span class="math inline">\(\{x^k\}\)</span> such that <span class="math inline">\(x^k \in x^0 + \sum_{i=1}^{k-1} a^i\nabla f(x^{i})\)</span>.</p>

<div class="theorem">
<p><span id="thm:slow" class="theorem"><strong>Theorem 1.2 </strong></span>For any <span class="math inline">\(k\)</span>, <span class="math inline">\(1 \leq k \leq \frac{1}{2} (n-1)\)</span>, and any <span class="math inline">\(x_0\in R^n\)</span>, there exists a continuous differentiable and gradient Lipschitz continuous convex function <span class="math inline">\(f(x)\)</span> such that for any first order method satisfying the Assumption LC, we have</p>
<p><span class="math display">\[ f(x_k) - f^* \geq \frac{3L||x^0 - x^*||^2}{32(k+1)^2}\]</span> <span class="math display">\[ ||x^k - x^*|| \geq \frac{1}{32} || x^0 - x^* ||^2,\]</span></p>
where <span class="math inline">\(L\)</span> is the gradient Lipschitz continuous parameter.
</div>


<div class="theorem">
<p><span id="thm:llow" class="theorem"><strong>Theorem 1.3 </strong></span>For any <span class="math inline">\(x_0\in R^n\)</span> and constant <span class="math inline">\(\ell&gt;0,L&gt;1\)</span>, there exists a continuous differentiable strongly convex function <span class="math inline">\(f(x)\)</span> such that for any first order method satisfying Assumption LC, we have</p>
<p><span class="math display">\[ f(x_k) - f^* \geq \frac{\ell}{2}(\frac{\sqrt{L/\ell}-1}{\sqrt{L/\ell}+1})^{2k}|| x^0 - x^* ||^2\]</span> <span class="math display">\[ ||x^k - x^*||^2 \geq (\frac{\sqrt{L/\ell}-1}{\sqrt{L/\ell}+1})^{2k} || x^0 - x^* ||^2,\]</span></p>
where <span class="math inline">\(L\)</span> and <span class="math inline">\(\ell\)</span> are the gradient Lipschitz continuous parameter and strongly convex parameter.
</div>
<p><br />
Theorem <a href="01-Gradient_Methods.html#thm:slow">1.2</a> and Theorem <a href="01-Gradient_Methods.html#thm:llow">1.3</a> leaves room for our next section’s topic - acceleartion.</p>
</div>
</div>
<div id="acceleartion" class="section level2">
<h2><span class="header-section-number">1.3</span> Acceleartion</h2>
<div id="motivation-for-acceleration." class="section level3">
<h3><span class="header-section-number">1.3.1</span> Motivation for acceleration.</h3>
<p>Apart from what we mentioned above the lower complexity bound, we note that even we can obtain linear rate of convergence, gradient descent method can still be dreadfully slow in practice. Let’s look at the example below.</p>

<div class="example">
<span id="ex:plaingd" class="example"><strong>Example 1.1 </strong></span>If <span class="math inline">\(f(x) = \frac{1}{2} x^TAx\)</span>, where <span class="math inline">\(A = \begin{pmatrix}200 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}\)</span>. And we run gradient descent method with starting point <span class="math inline">\(x^0 = (0.1,0.1)\)</span> and step-size <span class="math inline">\(\alpha = \frac{2}{201}\)</span>. If we run gradient descent method 100 times, we will get following results.
</div>

<p><img src="demo_files/figure-html/contour_g-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Figure above shows that the path of iterates is zig-zag, hence converging slowly to the global optimal solution <span class="math inline">\((0,0)\)</span>. The reason lies in the condition number <span class="math inline">\(\kappa = L/\ell\)</span>, which is too large. And in <span class="math display">\[f(x_k) - f(x^*) \leq \frac{L}{2}\big(\frac{L-\ell}{L+\ell}\big)^{2k}||x^0 - x^*||^2.\]</span> the shrinkage factor <span class="math inline">\(\frac{L-\ell}{L+\ell}\)</span> is close to <span class="math inline">\(1\)</span>, which means, you can gain little improvement in each iteration.</p>
<p>Intuitively, to get around this situation, we have to avoid “oscillation” phenomenon. One commonly used strategy is to the previous stage’s direction <span class="math inline">\(x^{k-1}-x^k\)</span> to modify the current direction <span class="math inline">\(\nabla f(x^k)\)</span>. We go along the composite direction <span class="math inline">\(\xi^k (x^{k-1}-x^k) + \zeta^k\nabla f(x^{k})\)</span> to find the <span class="math inline">\(x^{k+1}\)</span>.</p>
</div>
<div id="why-we-can-accelerate" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Why we can accelerate?</h3>
<p>Take the folowing example to illustrate.</p>

<div class="example">
<p><span id="ex:unnamed-chunk-9" class="example"><strong>Example 1.2 </strong></span>Consider using gradient descent methods to solve the problem shown below.</p>
<p><span class="math display">\[\mathop{\text{agrmin}}_{x\in R^n} \frac{1}{2}x^TAx - b^Tx\]</span></p>
<p>where <span class="math inline">\(\ell I_n \leq A \leq L I_n\)</span>. All that gradient descent does is to compute the sequence of points</p>
<p><span class="math display">\[ x^{k+1} = x^k - t^k \nabla f(x^k) \]</span>.</p>
<p>Let’s set <span class="math inline">\(t^k = t= 2/(\ell + L)\)</span> and run gradient descent with starting points <span class="math inline">\(x^0 = tb\)</span>. We can then check that</p>
<p><span class="math display">\[ x^k = \Big(\sum_{j=0}^k (I-A&#39;)^k\Big)b&#39; \]</span></p>
<p>where <span class="math inline">\(A′=tA\)</span> and <span class="math inline">\(b′=tb\)</span>. Since <span class="math inline">\(||A&#39;||&lt;1\)</span>, <span class="math inline">\(x^k \rightarrow x^* = A^{-1}b\)</span>. This is the generlization of following result <span class="math display">\[\frac{1}{x} = \sum_{k=0}^\infty (1-x)^k, \forall |x|&lt;1 .\]</span></p>
<p>Moreover, the approximation error when truncating the series at degree <span class="math inline">\(k\)</span> is <span class="math inline">\(O( (1-x)^k)).\)</span></p>
<p>So to improve on gradient descent it suffices to find a better low-degree approximation to the scalar function <span class="math inline">\(1/x\)</span>. Indeed, we can save a square root in the degree while achieving the same error by using <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a>. Chebyshev polynomials of the first kind takes the form of</p>
<p><span class="math display">\[
\begin{aligned}
T_{0}(x)&amp;=1\\
T_{1}(x)&amp;=x\\
T_{n+1}(x)&amp;=2xT_{n}(x)-T_{n-1}(x).
\end{aligned}
\]</span></p>
<p>The Chebyshev polynomials satisfy a simple recursive definition that defines the k-th degree polynomial in terms of the previous two polynomials. This means that accelerated gradient descent only needs the previous two gradients with suitable coefficients:</p>
<span class="math display">\[ x_k = x_{k-1} - \alpha_k \nabla f(x_{k-1}) + \beta_k \nabla f(x_{k-2}). \]</span> This conicides with the general form Nesterov Accelerated Gradient Descent Method(NAGD). Detailed discussion can be found <a href="http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html">here</a>.
</div>

</div>
<div id="heavy-ball-methods-v.s-nagd-method" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Heavy Ball Methods v.s NAGD Method</h3>
<p>Let’s put our intuition into concrete mathematical form, which gives rise to the Heavy Ball Method.</p>
<table style="width:11%;">
<colgroup>
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Heavy Ball Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Scheme</td>
<td>Set <span class="math inline">\(x^0 \in R^n\)</span>, and run <span class="math inline">\(x^{k+1} = x^k - [\alpha\nabla f(x^k) + \beta (x^{k-1} - x^k)]\)</span></td>
</tr>
</tbody>
</table>
<p>What Nesterov does is mcuh more “smart”. To be specific, instead of using current iterate’s gradient information, <span class="math inline">\(\nabla f(x^k)\)</span>, Nesterov suggests using the approximate position of <span class="math inline">\(x^{k+1}\)</span>, given by <span class="math inline">\(x^k + \gamma^{k-1}(x^{k-1} - x^k)\)</span>.</p>
<table style="width:11%;">
<colgroup>
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>NAGD Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Scheme</td>
<td>Set <span class="math inline">\(x^0 \in R^n\)</span>, and run <span class="math inline">\(x^{k+1} = x^k - \frac{1}{L}\nabla f[x^k + \gamma^{k-1}(x^{k-1} - x^k)] + \gamma^{k-1}(x^{k-1} - x^k)\)</span></td>
</tr>
</tbody>
</table>
<p>The NAGD Methods can be also seen as a two stage iterative methods, by re-constructing <span class="math inline">\(x^{k+1} = x^k - \frac{1}{L}\nabla f[x^k + \gamma^{k-1}(x^{k-1} - x^k)] + \gamma^{k-1}(x^{k-1} - x^k)\)</span> as</p>
<p><span class="math display">\[
\begin{cases}
  y^{k+1} &amp;= x^k - \alpha f(x^k)\; &amp;(1)\\
  x^{k+1} &amp;= (1 - \gamma^k)y^{k+1} + \gamma^k y^k\; &amp;(2)
\end{cases}
\]</span></p>
<ul>
<li><ol style="list-style-type: decimal">
<li>performs a simple step of gradient descent to go from <span class="math inline">\(x^k\)</span> to <span class="math inline">\(y^{k+1}\)</span> and then,</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>slides a little bit further than <span class="math inline">\(y^{k+1}\)</span> in the direction given by the previous iterate <span class="math inline">\(y^k\)</span>.</li>
</ol></li>
</ul>
<p><strong>Remark: Parameter Selection.</strong> The <span class="math inline">\(\alpha,\beta,\gamma^k\)</span> is given as follows to guarantee convergence.</p>
<p><span class="math display">\[
\begin{align}
&amp; \alpha = \frac{4}{L}\frac{1}{(1 + \frac{1}{\sqrt{L/\ell}})^2} \\
&amp; \beta = (1 - \frac{2}{\sqrt{L/\ell}+1})^2 \\
&amp; \gamma^k = \frac{1-\lambda^k}{\lambda^k + 1}
\end{align}
\]</span> where <span class="math inline">\(\lambda^0=0, \lambda^k = \frac{1+ \sqrt{1 + 4(\lambda^{k-1})^2}}{2}\)</span>.</p>
<p>We conclude this section by performing two methods on the problem of Example<a href="01-Gradient_Methods.html#ex:plaingd">1.1</a>.</p>
</div>
<div id="when-does-the-nagd-methods-fail" class="section level3">
<h3><span class="header-section-number">1.3.4</span> When does the NAGD Methods fail?</h3>

</div>
</div>
</div>
<h3> Test</h3>
<div id="refs" class="references">
<div id="ref-nesterov2013introductory">
<p>Nesterov, Yurii. 2013. <em>Introductory Lectures on Convex Optimization: A Basic Course</em>. Vol. 87. Springer Science &amp; Business Media.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="02-Block_Coordinate_Descent.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-Gradient_Methods.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
